0_1_rename_midi.py

import os
from pathlib import Path

def renombrar_extensiones():
    base_path = Path("data/maestro-v3.0.0")

    if not base_path.exists():
        print(f"‚ùå Error: No se encuentra la ruta {base_path.resolve()}")
        print("Aseg√∫rate de ejecutar este script desde la carpeta ra√≠z 'AMT_Piano_Sheet_Music'")
        return

    print(f"üìÇ Buscando archivos .midi en: {base_path}\n")

    contador = 0
    
    for archivo in base_path.rglob("*.midi"):
        nuevo_nombre = archivo.with_suffix(".mid")
        
        try:
            archivo.rename(nuevo_nombre)
            print(f"‚úÖ Renombrado: {archivo.name} -> {nuevo_nombre.name}")
            contador += 1
        except Exception as e:
            print(f"‚ùå Error al renombrar {archivo.name}: {e}")

    print("-" * 30)
    print(f"üéâ Proceso terminado. Se han renombrado {contador} archivos.")

if __name__ == "__main__":
    renombrar_extensiones()






02_resample_in_place.py

import librosa
import soundfile as sf
from pathlib import Path
from tqdm import tqdm
import os # Nueva importaci√≥n clave

# --- CONFIGURACI√ìN ---
TARGET_SR = 16000  # Frecuencia de muestreo objetivo: 16 kHz

def remuestrear_y_sobrescribir():
    # --- Configuraci√≥n de Rutas (Asegura la compatibilidad) ---
    project_root = Path(__file__).resolve().parent.parent 
    root_path = project_root / "AMT_Piano_Sheet_Music" / "data" / "maestro-v3.0.0"

    # --- 1. Crear la lista de archivos usando os.walk (M√©todo infalible) ---
    wav_files = []
    
    # Comprobaci√≥n de existencia (Si esto falla, el directorio ra√≠z no existe)
    if not root_path.exists():
        print(f"ERROR CR√çTICO: No se encontr√≥ la ruta principal: {root_path.resolve()}")
        return

    # os.walk recorre garantizadamente todos los subdirectorios
    for root, _, files in os.walk(root_path):
        for file in files:
            # A√±adimos solo los archivos que terminan en .wav (ignorando may√∫sculas/min√∫sculas)
            if file.lower().endswith(".wav"):
                wav_files.append(Path(root) / file) 
    # --------------------------------------------------------------------------

    print("-" * 50)
    print(f"üöÄ Iniciando remuestreo y sobrescritura de {len(wav_files)} archivos a {TARGET_SR} Hz.")
    print("üö® ADVERTENCIA: SE SOBREESCRIBIR√ÅN LOS ARCHIVOS ORIGINALES. üö®")
    print("-" * 50)
    
    if not wav_files:
        print("ERROR: La lista de archivos sigue vac√≠a. Verifica que los archivos .wav existan dentro de las carpetas de a√±o.")
        return

    contador_resampleado = 0
    contador_saltado = 0

    for wav_path in tqdm(wav_files, desc="Procesando Audios"):
        
        try:
            # 2. Leer SOLO el encabezado para chequear el SR original (r√°pido)
            _, original_sr = librosa.load(wav_path, sr=None, duration=0.1)
            
            # 3. Verificar si necesita remuestreo
            if original_sr == TARGET_SR:
                contador_saltado += 1
                continue 

            # 4. Cargar el audio completo y remuestrear a TARGET_SR (y mono por defecto)
            y, _ = librosa.load(wav_path, sr=TARGET_SR, mono=True)
            
            # 5. SOBREESCRIBIR el archivo original
            sf.write(wav_path, y, TARGET_SR, format='WAV')
            
            contador_resampleado += 1
            
        except Exception as e:
            print(f"\n‚ùå ERROR CR√çTICO procesando {wav_path.name}: {e}. Archivo no modificado.")

    print("-" * 50)
    print(f"üéâ Proceso terminado. Archivos remuestreados y sobrescritos: {contador_resampleado}")
    print(f"‚úÖ Archivos saltados (ya estaban a {TARGET_SR} Hz): {contador_saltado}")
    print("‚úîÔ∏è La carpeta de origen ahora solo contiene audios a 16 kHz.")

if __name__ == "__main__":
    remuestrear_y_sobrescribir()






03_preprocess.py

import os
import random
import numpy as np
import librosa
import librosa.display
import pretty_midi
import matplotlib.pyplot as plt
from pathlib import Path
from tqdm import tqdm

# --- CONFIGURACI√ìN DE AUDIO ---
SR = 16000           
HOP_LENGTH = 512     
# CQT CONFIG (Optimizado para piano 88 teclas)
MIN_NOTE = 'A0'      
N_BINS = 88          
BINS_PER_OCTAVE = 12 
MIN_MIDI = 21        
MAX_MIDI = 108       
NUM_CLASSES = 88     

def ask_percentage():
    while True:
        try:
            val = input("\nüìä ¬øQu√© porcentaje del dataset quieres procesar? (0.1 - 100): ")
            percent = float(val)
            if 0 < percent <= 100:
                return percent
        except ValueError: pass

def compute_cqt(audio_path):
    # Cargar audio
    y, _ = librosa.load(str(audio_path), sr=SR)
    
    # Calcular CQT
    cqt = librosa.cqt(
        y=y, 
        sr=SR, 
        hop_length=HOP_LENGTH, 
        fmin=librosa.note_to_hz(MIN_NOTE), 
        n_bins=N_BINS, 
        bins_per_octave=BINS_PER_OCTAVE
    )
    
    # Convertir a dB y Normalizar
    cqt_db = librosa.amplitude_to_db(np.abs(cqt), ref=np.max).T.astype(np.float32)
    
    # Normalizaci√≥n simple (0 a 1)
    cqt_db = (cqt_db + 80.0) / 80.0
    cqt_db = np.clip(cqt_db, 0, 1)
    
    return y, cqt_db

def add_soft_label(matrix, exact_frame, pitch_idx, num_frames, width=3):
    """
    Aplica etiquetas suaves (soft labels) decrecientes alrededor del frame exacto.
    Basado en la t√©cnica de High-Resolution (Kong et al / hFT-Transformer).
    """
    start_idx = int(np.floor(exact_frame - width))
    end_idx = int(np.ceil(exact_frame + width))

    for i in range(start_idx, end_idx + 1):
        if 0 <= i < num_frames:
            dist = abs(i - exact_frame)
            val = 1.0 - (dist / width)
            if val > 0:
                # Usamos max para no sobrescribir si ya hab√≠a una nota m√°s cercana
                matrix[i, pitch_idx] = max(matrix[i, pitch_idx], val)

def compute_labels(midi_path, num_frames):
    try:
        pm = pretty_midi.PrettyMIDI(str(midi_path))
    except Exception as e:
        print(f"Error MIDI {midi_path}: {e}")
        return None, None, None, None

    # Inicializar matrices 
    # NOTA: Onset y Offset ahora son float32 para soportar decimales (0.9, 0.5, etc)
    onset_matrix = np.zeros((num_frames, NUM_CLASSES), dtype=np.float32)
    offset_matrix = np.zeros((num_frames, NUM_CLASSES), dtype=np.float32)
    frame_matrix = np.zeros((num_frames, NUM_CLASSES), dtype=np.int8)
    velocity_matrix = np.zeros((num_frames, NUM_CLASSES), dtype=np.float32)

    time_per_frame = HOP_LENGTH / SR
    J_WIDTH = 3 # Ancho de la ventana de suavizado (paper standard)

    for note in pm.instruments[0].notes:
        if note.pitch < MIN_MIDI or note.pitch > MAX_MIDI:
            continue
            
        pitch_idx = note.pitch - MIN_MIDI
        
        # Tiempos exactos en frames (con decimales)
        start_frame_float = note.start / time_per_frame
        end_frame_float = note.end / time_per_frame
        
        # Tiempos enteros para la matriz de FRAME (sostenimiento)
        start_frame_int = int(round(start_frame_float))
        end_frame_int = int(round(end_frame_float))
        
        # Limites seguros
        start_frame_int = max(0, min(start_frame_int, num_frames - 1))
        end_frame_int = max(0, min(end_frame_int, num_frames - 1))

        if end_frame_int <= start_frame_int:
            end_frame_int = start_frame_int + 1
        
        # 1. FRAME (Binario: Sostenimiento)
        frame_matrix[start_frame_int:end_frame_int, pitch_idx] = 1
        
        # 2. ONSET (High-Res Soft Label)
        add_soft_label(onset_matrix, start_frame_float, pitch_idx, num_frames, width=J_WIDTH)
        
        # 3. OFFSET (High-Res Soft Label)
        add_soft_label(offset_matrix, end_frame_float, pitch_idx, num_frames, width=J_WIDTH)
        
        # 4. VELOCITY (En el frame de inicio entero)
        if start_frame_int < num_frames:
            velocity_matrix[start_frame_int, pitch_idx] = note.velocity / 127.0

    return onset_matrix, offset_matrix, frame_matrix, velocity_matrix

def save_verification_plot(audio, cqt, onsets, frames, velocities, file_id, save_path):
    # Definir duraci√≥n exacta en segundos
    duration_sec = len(audio) / SR
    extent = [0, duration_sec, 0, 88]

    # Cortamos a 10 segundos
    zoom_sec = 10
    if duration_sec > zoom_sec:
        max_sample = int(zoom_sec * SR)
        max_frame = int(zoom_sec * SR / HOP_LENGTH)
        
        audio_cut = audio[:max_sample]
        duration_cut = len(audio_cut) / SR
        extent_cut = [0, duration_cut, 0, 88]
        
        cqt_cut = cqt[:max_frame].T
        frames_cut = frames[:max_frame].T
        onsets_cut = onsets[:max_frame].T
        vel_cut = velocities[:max_frame].T
    else:
        audio_cut = audio
        extent_cut = extent
        cqt_cut = cqt.T
        frames_cut = frames.T
        onsets_cut = onsets.T
        vel_cut = velocities.T

    fig, ax = plt.subplots(5, 1, figsize=(12, 12), sharex=True)
    plt.subplots_adjust(hspace=0.2)
    
    ax[0].set_title(f"1. Audio Waveform - {file_id}")
    librosa.display.waveshow(audio_cut, sr=SR, ax=ax[0], color='#444444')
    ax[0].set_ylabel("Amplitude")
    
    ax[1].set_title("2. Input CQT")
    ax[1].imshow(cqt_cut, aspect='auto', origin='lower', extent=extent_cut, cmap='magma', interpolation='nearest')
    
    ax[2].set_title("3. Target: Frames (Binary)")
    ax[2].imshow(frames_cut, aspect='auto', origin='lower', extent=extent_cut, cmap='binary', interpolation='nearest')
    
    ax[3].set_title("4. Target: Onsets (High-Res Soft Labels)")
    ax[3].imshow(onsets_cut, aspect='auto', origin='lower', extent=extent_cut, cmap='Reds', interpolation='nearest')
    
    ax[4].set_title("5. Target: Velocity")
    im = ax[4].imshow(vel_cut, aspect='auto', origin='lower', extent=extent_cut, cmap='viridis', interpolation='nearest')
    
    ax[4].set_xlabel("Time (seconds)")
    
    output_file = save_path / f"debug_viz_{file_id}.png"
    plt.savefig(output_file)
    plt.close()
    print(f"   üì∏ Verificaci√≥n guardada: {output_file.name}")

def procesar_dataset():
    root_path = Path("data/maestro-v3.0.0") 
    output_base = Path("processed_data")
    
    folders = ["inputs_cqt", "targets_onset", "targets_offset", "targets_frame", "targets_velocity"]
    for sub in folders:
        (output_base / sub).mkdir(parents=True, exist_ok=True)
    
    viz_path = output_base / "debug_visualizations"
    viz_path.mkdir(parents=True, exist_ok=True)

    all_wavs = list(root_path.rglob("*.wav"))
    
    if not all_wavs:
        print("‚ùå No se encontraron archivos .wav")
        return

    percent = ask_percentage()
    num_to_process = int(len(all_wavs) * (percent / 100))
    if num_to_process < 1: num_to_process = 1
    
    random.shuffle(all_wavs)
    selected_wavs = all_wavs[:num_to_process]

    print(f"\nüöÄ Procesando {num_to_process} archivos (Modo High-Resolution)...")
    print(f"üìÇ Guardando en: {output_base.resolve()}")

    viz_count = 0 
    MAX_VIZ = 3

    for wav_path in tqdm(selected_wavs):
        midi_path = wav_path.with_suffix(".mid")
        if not midi_path.exists(): midi_path = wav_path.with_suffix(".midi")
        if not midi_path.exists(): continue

        file_id = f"{wav_path.parent.name}_{wav_path.stem}"

        # 1. Audio + CQT
        audio_raw, cqt = compute_cqt(wav_path)
        
        # 2. Labels (Con l√≥gica High-Res)
        onsets, offsets, frames, vels = compute_labels(midi_path, cqt.shape[0])

        if onsets is None: continue

        # 3. Guardar Datos
        np.save(output_base / "inputs_cqt" / f"{file_id}.npy", cqt)
        np.save(output_base / "targets_onset" / f"{file_id}.npy", onsets)
        np.save(output_base / "targets_offset" / f"{file_id}.npy", offsets)
        np.save(output_base / "targets_frame" / f"{file_id}.npy", frames)
        np.save(output_base / "targets_velocity" / f"{file_id}.npy", vels)

        # 4. Visualizaci√≥n
        if viz_count < MAX_VIZ:
            save_verification_plot(audio_raw, cqt, onsets, frames, vels, file_id, viz_path)
            viz_count += 1

    print("\n‚úÖ ¬°Proceso High-Res completado correctamente!")

if __name__ == "__main__":
    procesar_dataset()





04_inspect_grid.py

import numpy as np
import matplotlib.pyplot as plt
import librosa
from pathlib import Path
import random

# --- CONFIGURACI√ìN ---
SR = 16000
HOP_LENGTH = 512
FRAME_TIME = HOP_LENGTH / SR  # 0.032s

def midi_to_name(midi_number):
    return librosa.midi_to_note(midi_number + 21)

def plot_paper_style_grid():
    base_path = Path("processed_data")
    if not base_path.exists():
        print("‚ùå Ejecuta primero el preprocesamiento.")
        return

    # 1. Cargar una canci√≥n al azar
    files = list((base_path / "inputs_cqt").glob("*.npy"))
    if not files:
        print("No hay datos procesados.")
        return

    chosen_file = random.choice(files)
    fid = chosen_file.name
    print(f"Analizando: {fid}")

    # Cargar matrices
    try:
        onsets = np.load(base_path / "targets_onset" / fid)
        frames = np.load(base_path / "targets_frame" / fid)
        offsets = np.load(base_path / "targets_offset" / fid)
        vels = np.load(base_path / "targets_velocity" / fid)
    except FileNotFoundError:
        print("‚ùå Faltan archivos targets.")
        return

    # 2. Buscar un "momento interesante"
    activity = frames.sum(axis=1)
    active_idxs = np.where(activity > 0)[0]
    
    if len(active_idxs) == 0:
        print("Canci√≥n vac√≠a (silencio).")
        return

    center_idx = random.choice(active_idxs)
    
    # 3. Definir ventana de ZOOM
    WINDOW = 14 
    start = max(0, center_idx - WINDOW // 2)
    end = min(len(frames), start + WINDOW)
    
    # Recortar datos y Transponer
    sl_onset = onsets[start:end].T
    sl_frame = frames[start:end].T
    sl_offset = offsets[start:end].T
    sl_vel = vels[start:end].T

    # 4. Filtrar teclas inactivas
    total_activity = sl_onset + sl_frame + sl_offset
    active_keys_idx = np.where(total_activity.sum(axis=1) > 0)[0]
    
    if len(active_keys_idx) == 0:
        print("Slice vac√≠o, reintentando...")
        return plot_paper_style_grid()

    sl_onset = sl_onset[active_keys_idx]
    sl_frame = sl_frame[active_keys_idx]
    sl_offset = sl_offset[active_keys_idx]
    sl_vel = sl_vel[active_keys_idx]
    
    note_names = [librosa.midi_to_note(idx + 21) for idx in active_keys_idx]

    # --- GRAFICADO ---
    fig, axes = plt.subplots(4, 1, figsize=(12, 10), sharex=True)
    plt.subplots_adjust(hspace=0.1)
    
    times = np.arange(start, end) * FRAME_TIME
    time_labels = [f"{t:.3f}s" for t in times]

    def plot_matrix(ax, data, title, cmap, is_float=False):
        ax.set_ylabel(title, fontsize=12, fontweight='bold', rotation=0, labelpad=40)
        ax.set_yticks(np.arange(len(note_names)))
        ax.set_yticklabels(note_names)
        
        # Grid
        ax.set_xticks(np.arange(len(time_labels)))
        ax.set_xticklabels(time_labels, rotation=45)
        ax.set_xticks(np.arange(-0.5, len(time_labels), 1), minor=True)
        ax.set_yticks(np.arange(-0.5, len(note_names), 1), minor=True)
        ax.grid(which='minor', color='black', linestyle='-', linewidth=1)
        ax.tick_params(which='minor', bottom=False, left=False)

        # Poner valores num√©ricos
        for i in range(data.shape[0]): # Pitch
            for j in range(data.shape[1]): # Time
                val = data[i, j]
                if val > 0:
                    text_color = 'black'
                    # Si es float, mostramos 2 decimales. Si no, entero.
                    txt = f"{val:.2f}" if is_float else f"{int(val)}"
                    # Para floats peque√±os (ej. 0.05), quitamos el '0' del principio para ahorrar espacio si quieres
                    if is_float and val < 1: txt = f"{val:.2f}".lstrip('0') 
                    
                    rect = plt.Rectangle((j-0.5, i-0.5), 1, 1, facecolor=cmap, alpha=0.3 + (val*0.4)) # Alpha din√°mico seg√∫n intensidad
                    ax.add_patch(rect)
                    ax.text(j, i, txt, ha='center', va='center', color=text_color, fontweight='bold', fontsize=9)
                else:
                    ax.text(j, i, "0", ha='center', va='center', color='#cccccc', fontsize=8)

        ax.set_xlim(-0.5, len(time_labels)-0.5)
        ax.set_ylim(-0.5, len(note_names)-0.5)

    # 1. Onset (AHORA ES FLOAT)
    plot_matrix(axes[0], sl_onset, "ONSET\n(High-Res)", "orange", is_float=True)
    # 2. Velocity (Float)
    plot_matrix(axes[1], sl_vel, "VELOCITY", "cyan", is_float=True)
    # 3. Offset (AHORA ES FLOAT)
    plot_matrix(axes[2], sl_offset, "OFFSET\n(High-Res)", "yellow", is_float=True)
    # 4. Frame (Sigue siendo Binario 0/1)
    plot_matrix(axes[3], sl_frame, "FRAME", "green", is_float=False)

    axes[0].set_title(f"Visualizaci√≥n High-Resolution (Paper Style) - {fid}", pad=20)
    plt.xlabel("Tiempo (Segundos)")
    
    save_path = base_path / "debug_visualizations" / f"paper_grid_HR_{fid}.png"
    plt.savefig(save_path, bbox_inches='tight')
    plt.close()
    print(f"‚úÖ Gr√°fico High-Resolution guardado en: {save_path}")

if __name__ == "__main__":
    plot_paper_style_grid()



05_analyze_data.py

import os
import numpy as np
import glob
import sys


BASE_DIR = "processed_data"

FOLDERS = {
    "cqt":      os.path.join(BASE_DIR, "inputs_cqt"),
    "onset":    os.path.join(BASE_DIR, "targets_onset"),     
    "offset":   os.path.join(BASE_DIR, "targets_offset"),   
    "frame":    os.path.join(BASE_DIR, "targets_frame"),     
    "velocity": os.path.join(BASE_DIR, "targets_velocity")
}

def analyze_dataset():
    print(f"--- ANALIZANDO DATOS EN: {BASE_DIR} ---\n")

    # 1. Obtener lista de archivos CQT (Input principal)
    # Buscamos todos los .npy en la carpeta de inputs
    cqt_files = sorted(glob.glob(os.path.join(FOLDERS["cqt"], "*.npy")))
    
    if not cqt_files:
        print(f"ERROR: No se encontraron archivos .npy en {FOLDERS['cqt']}")
        return

    print(f"Total de archivos de entrada (CQT) encontrados: {len(cqt_files)}")
    print("-" * 60)

    # Variables para estad√≠sticas globales
    total_frames = 0
    errors_found = 0
    
    # Iteramos sobre cada archivo
    for i, cqt_path in enumerate(cqt_files):
        filename = os.path.basename(cqt_path)
        
        # Intentamos cargar todos los archivos correspondientes a este track
        try:
            # Asumimos que el nombre del archivo es igual en todas las carpetas
            # Si en cqt se llama "track1.npy", en onset buscamos "track1.npy"
            paths = {
                "cqt": cqt_path,
                "onset": os.path.join(FOLDERS["onset"], filename),
                "offset": os.path.join(FOLDERS["offset"], filename),
                "frame": os.path.join(FOLDERS["frame"], filename),
                "velocity": os.path.join(FOLDERS["velocity"], filename)
            }
            
            # Cargar datos
            data = {}
            for key, p in paths.items():
                if not os.path.exists(p):
                    raise FileNotFoundError(f"Falta archivo: {p}")
                data[key] = np.load(p)

            # --- AN√ÅLISIS INDIVIDUAL ---
            
            # 1. Chequeo de Shapes (Dimensiones)
            # Asumimos shape [Time, Freq] o [Freq, Time]. 
            # Detectamos cu√°l es tiempo: usualmente es la dimensi√≥n variable (la m√°s larga o distinta de 88)
            cqt_shape = data["cqt"].shape
            
            # Buscamos la dimensi√≥n de tiempo en el CQT (asumiendo que freq es 88)
            if cqt_shape[0] == 88:
                time_dim_idx = 1
                freq_dim_idx = 0
            else:
                time_dim_idx = 0
                freq_dim_idx = 1
            
            time_frames = cqt_shape[time_dim_idx]
            freq_bins = cqt_shape[freq_dim_idx]
            
            total_frames += time_frames

            # Verificar consistencia temporal entre Input y Targets
            # Todos los targets deben tener el mismo n√∫mero de frames que el CQT
            mismatches = []
            for key in ["onset", "offset", "frame", "velocity"]:
                # Asumiendo targets siempre son [Time, 88] o [88, Time], buscamos la dim que coincida con time_frames
                target_shape = data[key].shape
                if time_frames not in target_shape:
                    mismatches.append(f"{key}: {target_shape}")
            
            if mismatches:
                print(f"[ERROR] {filename} - Desajuste de tiempo: CQT tiene {time_frames} frames, pero: {mismatches}")
                errors_found += 1
                continue

            # 2. Imprimir detalles solo del primer archivo (para inspecci√≥n visual)
            if i == 0:
                print(f"\n>>> INFORME DETALLADO DEL PRIMER ARCHIVO: {filename} <<<")
                print(f"{'TIPO':<10} | {'SHAPE':<15} | {'DTYPE':<10} | {'MIN':<8} | {'MAX':<8} | {'MEAN':<8}")
                print("-" * 75)
                for key, arr in data.items():
                    print(f"{key:<10} | {str(arr.shape):<15} | {str(arr.dtype):<10} | {arr.min():.2f}     | {arr.max():.2f}     | {arr.mean():.4f}")
                print("-" * 75)
                
                # Advertencias inteligentes
                if data["cqt"].max() > 10.0:
                    print("‚ö†Ô∏è ADVERTENCIA: Los valores del CQT parecen muy altos (no est√°n normalizados entre 0 y 1). Esto puede dificultar el entrenamiento.")
                if data["onset"].max() > 1:
                    print("‚ö†Ô∏è ADVERTENCIA: Los targets de Onset no son binarios (0 o 1). ¬øQuiz√°s son √≠ndices midi?")
                if freq_bins != 88:
                    print(f"‚ö†Ô∏è ADVERTENCIA: Se detectaron {freq_bins} bins de frecuencia. El modelo UNet est√°ndar espera 88.")
                print("\nAnalizando el resto de archivos (solo se mostrar√°n errores)...")

        except FileNotFoundError as e:
            print(f"[FALTA ARCHIVO] Para {filename}: {e}")
            errors_found += 1
        except Exception as e:
            print(f"[ERROR DE LECTURA] En {filename}: {e}")
            errors_found += 1

    # --- RESUMEN FINAL ---
    print("\n" + "="*30)
    print("RESUMEN DEL DATASET")
    print("="*30)
    print(f"Total Tracks procesados: {len(cqt_files)}")
    print(f"Total Frames (Tiempo):   {total_frames}")
    if len(cqt_files) > 0:
        print(f"Promedio Frames/Track:   {total_frames / len(cqt_files):.0f}")
    
    if errors_found == 0:
        print("\n‚úÖ ¬°TODO PARECE CORRECTO! Las dimensiones coinciden.")
    else:
        print(f"\n‚ùå SE ENCONTRARON {errors_found} ERRORES. Revisa los logs de arriba.")

if __name__ == "__main__":
    analyze_dataset()

-------------POR PANTALLA --------------
--- ANALIZANDO DATOS EN: processed_data ---

Total de archivos de entrada (CQT) encontrados: 63
------------------------------------------------------------

>>> INFORME DETALLADO DEL PRIMER ARCHIVO: 2004_MIDI-Unprocessed_SMF_02_R1_2004_01-05_ORIG_MID--AUDIO_02_R1_2004_08_Track08_wav.npy <<<
TIPO       | SHAPE           | DTYPE      | MIN      | MAX      | MEAN
---------------------------------------------------------------------------
cqt        | (6081, 88)      | float32    | 0.00     | 1.00     | 0.4380
onset      | (6081, 88)      | float32    | 0.00     | 1.00     | 0.0159
offset     | (6081, 88)      | float32    | 0.00     | 1.00     | 0.0159
frame      | (6081, 88)      | int8       | 0.00     | 1.00     | 0.0220
velocity   | (6081, 88)      | float32    | 0.00     | 0.83     | 0.0028
---------------------------------------------------------------------------

Analizando el resto de archivos (solo se mostrar√°n errores)...

==============================
RESUMEN DEL DATASET
==============================
Total Tracks procesados: 63
Total Frames (Tiempo):   980304
Promedio Frames/Track:   15560

06_training.py

#Quiero experimentar en este problema de amt_piano to midi con la arquitectura unet + bilstm , una crnn  
pasame el training mas optimo para mi modelo , ten en cuenta 
============================================================
CPU INFO
============================================================
Procesador: Intel64 Family 6 Model 165 Stepping 2, GenuineIntel
Arquitectura: AMD64
N√∫cleos f√≠sicos: 6
N√∫cleos l√≥gicos: 12
Frecuencia CPU (MHz): 2592.0

============================================================
MEMORIA RAM
============================================================
Total (GB): 15.78
Disponible (GB): 6.21

============================================================
GPU INFO
============================================================
ID GPU: 0
Modelo: NVIDIA GeForce GTX 1650 Ti
VRAM Total (GB): 4.00
VRAM Usada (GB): 0.09
VRAM Libre (GB): 3.76
Temperatura: 48.0 ¬∞C
----------------------------------------

============================================================
CUDA INFO
============================================================
Sat Dec  6 00:30:00 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 577.03                 Driver Version: 577.03         CUDA Version: 12.9     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA GeForce GTX 1650 Ti   WDDM  |   00000000:01:00.0  On |                  N/A |
| N/A   48C    P8              3W /   50W |      88MiB /   4096MiB |      4%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+

+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
+-----------------------------------------------------------------------------------------+


============================================================
VERSIONES DE LIBRER√çAS
============================================================
Python: 3.12.6
PyTorch: 2.7.1+cu118
CUDA disponible: True
Versi√≥n CUDA (PyTorch): 11.8
N√∫mero de GPUs detectadas: 1
GPU actual: NVIDIA GeForce GTX 1650 Ti
TensorFlow no est√° instalado.
