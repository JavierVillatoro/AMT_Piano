{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09773dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Instalar librer√≠a de evaluaci√≥n musical\n",
    "!pip install mir_eval\n",
    "\n",
    "# 2. Descomprimir el dataset\n",
    "# IMPORTANTE: Aseg√∫rate de que la ruta del input coincida con donde Kaggle mont√≥ tu dataset.\n",
    "# Por lo general es /kaggle/input/nombre-de-tu-dataset/processed_data_HPPNET_100.rar\n",
    "import os\n",
    "if not os.path.exists(\"/kaggle/working/processed_data_HPPNET_100\"):\n",
    "    print(\"üìÇ Descomprimiendo dataset... esto puede tardar un minuto.\")\n",
    "    # Ajusta 'tu-dataset-name' al nombre real en Kaggle\n",
    "    !unrar x \"/kaggle/input/tu-dataset-name/processed_data_HPPNET_100.rar\" \"/kaggle/working/\"\n",
    "    print(\"‚úÖ Descompresi√≥n terminada.\")\n",
    "else:\n",
    "    print(\"üìÇ El dataset ya existe, saltando descompresi√≥n.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a3c262",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import mir_eval \n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import sys\n",
    "from scipy.signal import find_peaks  # <--- NUEVO: Para Peak Picking\n",
    "\n",
    "# ==========================================\n",
    "# 0. CONFIGURACI√ìN Y EST√ÅNDARES\n",
    "# ==========================================\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"‚öôÔ∏è Usando dispositivo: {DEVICE}\")\n",
    "\n",
    "SEED = 42\n",
    "SR = 16000           \n",
    "HOP_LENGTH = 512     \n",
    "SEGMENT_FRAMES = 320 \n",
    "BINS_PER_OCTAVE = 12  \n",
    "# Nota: En Kaggle working directory es donde descomprimimos\n",
    "DATA_PATH = Path(\"/kaggle/working/processed_data_HPPNET_100\") \n",
    "\n",
    "# Hyperpar√°metros Optimizados para Kaggle\n",
    "BATCH_SIZE = 32           # Subido de 4 a 32 para aprovechar GPU P100/T4\n",
    "FINAL_EPOCHS = 50         \n",
    "LEARNING_RATE = 0.0006    \n",
    "PATIENCE_LR = 5           # Un poco m√°s de paciencia\n",
    "FACTOR_LR = 0.5           \n",
    "NUM_WORKERS = 4           # Kaggle tiene buena CPU I/O\n",
    "\n",
    "# Umbrales\n",
    "THRESHOLD_ONSET = 0.35    # Ajustado para Peak Picking\n",
    "THRESHOLD_FRAME = 0.6     #ANTES 0.5\n",
    "THRESHOLD_OFFSET = 0.4\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(SEED)\n",
    "\n",
    "# ==========================================\n",
    "# 1. DATASET\n",
    "# ==========================================\n",
    "class PianoDataset(Dataset):\n",
    "    def __init__(self, processed_dir, split='train', val_split=0.15):\n",
    "        self.processed_dir = Path(processed_dir)\n",
    "        p = self.processed_dir / \"inputs_hcqt\"\n",
    "        if not p.exists(): raise RuntimeError(f\"‚ùå Ruta no existe: {p}\")\n",
    "        \n",
    "        all_files = sorted(list(p.glob(\"*.npy\")))\n",
    "        if len(all_files) == 0: raise RuntimeError(f\"‚ùå No se encontraron archivos .npy en {p}\")\n",
    "        \n",
    "        random.Random(SEED).shuffle(all_files)\n",
    "        split_idx = int(len(all_files) * (1 - val_split))\n",
    "        self.files = all_files[:split_idx] if split == 'train' else all_files[split_idx:]\n",
    "        \n",
    "        self.segments = []\n",
    "        # Pre-calculamos segmentos\n",
    "        print(f\"   Calculando segmentos para {split}...\")\n",
    "        for idx, f in enumerate(self.files):\n",
    "            try:\n",
    "                # mmap_mode='r' lee solo la cabecera para ser r√°pido\n",
    "                shape = np.load(f, mmap_mode='r').shape\n",
    "                n_frames = shape[0]\n",
    "                num_clips = math.ceil(n_frames / SEGMENT_FRAMES)\n",
    "                for i in range(num_clips):\n",
    "                    start = i * SEGMENT_FRAMES\n",
    "                    end = min(start + SEGMENT_FRAMES, n_frames)\n",
    "                    if (end - start) > 30: \n",
    "                        self.segments.append((idx, start, end))\n",
    "            except: continue\n",
    "        print(f\"   ‚úÖ {split.upper()}: {len(self.segments)} segmentos cargados.\")\n",
    "\n",
    "    def __len__(self): return len(self.segments)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_idx, start, end = self.segments[idx]\n",
    "        fid = self.files[file_idx].name\n",
    "        try:\n",
    "            base = self.processed_dir\n",
    "            # Carga con mmap para velocidad\n",
    "            hcqt = np.load(base / \"inputs_hcqt\" / fid, mmap_mode='r')[start:end] \n",
    "            onset = np.load(base / \"targets_onset\" / fid, mmap_mode='r')[start:end]\n",
    "            frame = np.load(base / \"targets_frame\" / fid, mmap_mode='r')[start:end]\n",
    "            offset = np.load(base / \"targets_offset\" / fid, mmap_mode='r')[start:end]\n",
    "            vel = np.load(base / \"targets_velocity\" / fid, mmap_mode='r')[start:end]\n",
    "            \n",
    "            curr_len = hcqt.shape[0]\n",
    "            if curr_len < SEGMENT_FRAMES:\n",
    "                pad = SEGMENT_FRAMES - curr_len\n",
    "                hcqt = np.pad(hcqt, ((0, pad), (0,0), (0,0)))\n",
    "                onset = np.pad(onset, ((0, pad), (0,0)))\n",
    "                frame = np.pad(frame, ((0, pad), (0,0)))\n",
    "                offset = np.pad(offset, ((0, pad), (0,0)))\n",
    "                vel = np.pad(vel, ((0, pad), (0,0)))\n",
    "            \n",
    "            hcqt_t = torch.tensor(hcqt).permute(2, 1, 0).float()\n",
    "            \n",
    "            return {\n",
    "                \"hcqt\": hcqt_t,\n",
    "                \"onset\": torch.tensor(onset).float(),\n",
    "                \"frame\": torch.tensor(frame).float(),\n",
    "                \"offset\": torch.tensor(offset).float(),\n",
    "                \"velocity\": torch.tensor(vel).float()\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {fid}: {e}\")\n",
    "            z = torch.zeros(SEGMENT_FRAMES, 88)\n",
    "            return {\"hcqt\": torch.zeros(3, 88, SEGMENT_FRAMES), \"onset\": z, \"frame\": z, \"offset\": z, \"velocity\": z}\n",
    "\n",
    "# ==========================================\n",
    "# 2. ARQUITECTURA FINAL (RESIDUAL + HDCONV + INSTANCENORM)\n",
    "# ==========================================\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.25, gamma=2.0):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        p = torch.sigmoid(inputs)\n",
    "        ce_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction=\"none\")\n",
    "        p_t = p * targets + (1 - p) * (1 - targets)\n",
    "        loss = ce_loss * ((1 - p_t) ** self.gamma)\n",
    "        if self.alpha >= 0:\n",
    "            alpha_t = self.alpha * targets + (1 - self.alpha) * (1 - targets)\n",
    "            loss = alpha_t * loss\n",
    "        return loss.mean()\n",
    "\n",
    "# --- NUEVO: Bloque Residual ---\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_c, out_c):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_c, out_c, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn1 = nn.InstanceNorm2d(out_c, affine=True)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(out_c, out_c, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn2 = nn.InstanceNorm2d(out_c, affine=True)\n",
    "        \n",
    "        self.downsample = None\n",
    "        if in_c != out_c:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(in_c, out_c, kernel_size=1, bias=False),\n",
    "                nn.InstanceNorm2d(out_c, affine=True)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "        out += identity  # <--- RESIDUAL CONNECTION\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "# --- HDConv Corregida (Sin dilataci√≥n negativa) ---\n",
    "class HDConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.convs = nn.ModuleList()\n",
    "        # Arm√≥nicos superiores (el 0.5, 1 y 2 ya vienen en el input HCQT)\n",
    "        harmonics = [1, 2, 3, 4] \n",
    "        \n",
    "        for h in harmonics:\n",
    "            if h == 1:\n",
    "                d = 1 \n",
    "            else:\n",
    "                d = int(np.round(BINS_PER_OCTAVE * np.log2(h)))\n",
    "            \n",
    "            # Padding asim√©trico para mantener tama√±o con dilataci√≥n vertical\n",
    "            self.convs.append(nn.Conv2d(\n",
    "                in_channels, out_channels, \n",
    "                kernel_size=(3, 3), \n",
    "                padding=(d, 1), \n",
    "                dilation=(d, 1)\n",
    "            ))\n",
    "        self.fusion = nn.Conv2d(out_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_sum = sum([conv(x) for conv in self.convs])\n",
    "        return self.fusion(x_sum)\n",
    "\n",
    "class AcousticModel(nn.Module):\n",
    "    def __init__(self, in_channels, base_channels):\n",
    "        super().__init__()\n",
    "        # Entrada: Adapta HCQT (3 canales) a Base Channels\n",
    "        self.input_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, base_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.InstanceNorm2d(base_channels, affine=True),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Bloques Residuales para profundizar sin perder se√±al\n",
    "        self.res1 = ResidualBlock(base_channels, base_channels)\n",
    "        self.res2 = ResidualBlock(base_channels, base_channels)\n",
    "        \n",
    "        # Visi√≥n Arm√≥nica\n",
    "        self.hdc = HDConv(base_channels, base_channels)\n",
    "        self.hdc_bn = nn.InstanceNorm2d(base_channels, affine=True)\n",
    "        self.hdc_relu = nn.ReLU()\n",
    "        \n",
    "        # Contexto (M√°s residuales)\n",
    "        self.context = nn.Sequential(\n",
    "            ResidualBlock(base_channels, base_channels),\n",
    "            ResidualBlock(base_channels, base_channels),\n",
    "            ResidualBlock(base_channels, base_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_conv(x)\n",
    "        x = self.res1(x)\n",
    "        x = self.res2(x)\n",
    "        \n",
    "        # Sumamos la visi√≥n arm√≥nica (Residual Style)\n",
    "        x_hdc = self.hdc(x)\n",
    "        x_hdc = self.hdc_relu(self.hdc_bn(x_hdc))\n",
    "        x = x + x_hdc \n",
    "        \n",
    "        x = self.context(x)\n",
    "        return x\n",
    "\n",
    "class FG_LSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        # LSTM Bidireccional\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.proj = nn.Linear(hidden_dim * 2, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        b, c, f, t = x.shape\n",
    "        # Permutar para LSTM (Batch*Freq, Time, Channels)\n",
    "        x = x.permute(0, 2, 3, 1).reshape(b * f, t, c)\n",
    "        self.lstm.flatten_parameters()\n",
    "        output, _ = self.lstm(x)\n",
    "        output = self.proj(output)\n",
    "        output = output.view(b, f, t)\n",
    "        return output.permute(0, 2, 1) \n",
    "\n",
    "class HPPNet(nn.Module):\n",
    "    def __init__(self, in_channels=4, base_channels=24, lstm_hidden=128):  # <--- LSTM SUBIDO A 128\n",
    "        super().__init__()\n",
    "        self.acoustic_onset = AcousticModel(in_channels, base_channels)\n",
    "        self.acoustic_other = AcousticModel(in_channels, base_channels)\n",
    "        \n",
    "        self.head_onset = FG_LSTM(base_channels, lstm_hidden)\n",
    "        \n",
    "        concat_dim = base_channels * 2\n",
    "        self.head_frame = FG_LSTM(concat_dim, lstm_hidden)\n",
    "        self.head_offset = FG_LSTM(concat_dim, lstm_hidden)\n",
    "        self.head_velocity = FG_LSTM(concat_dim, lstm_hidden)\n",
    "\n",
    "    def forward(self, x):\n",
    "        feat_onset = self.acoustic_onset(x)\n",
    "        logits_onset = self.head_onset(feat_onset)\n",
    "        \n",
    "        feat_onset_detached = feat_onset.detach()\n",
    "        feat_other = self.acoustic_other(x)\n",
    "        feat_combined = torch.cat([feat_other, feat_onset_detached], dim=1)\n",
    "        \n",
    "        logits_frame = self.head_frame(feat_combined)\n",
    "        logits_offset = self.head_offset(feat_combined)\n",
    "        \n",
    "        #logits_offset_raw = self.head_offset(feat_combined)\n",
    "        #logits_offset = logits_offset_raw * torch.sigmoid(logits_frame.detach())\n",
    "        \n",
    "        logits_velocity = self.head_velocity(feat_combined)\n",
    "        \n",
    "        return logits_onset, logits_frame, logits_offset, logits_velocity\n",
    "\n",
    "# ==========================================\n",
    "# 3. UTILS (CON PEAK PICKING)\n",
    "# ==========================================\n",
    "def tensor_to_notes(onset_pred, frame_pred, offset_pred, velocity_pred=None, t_onset=0.35, t_frame=0.6, t_offset=0.4):\n",
    "    \"\"\"\n",
    "    Decodificaci√≥n con condicionamiento expl√≠cito de Offset.\n",
    "    Nota: He a√±adido offset_pred a los argumentos.\n",
    "    \"\"\"\n",
    "    notes = []\n",
    "    for pitch in range(88):\n",
    "        # 1. Peak Picking (Igual que antes)\n",
    "        peaks, _ = find_peaks(onset_pred[:, pitch], height=t_onset, distance=2)\n",
    "        \n",
    "        for onset_frame in peaks:\n",
    "            # 2. Validaci√≥n de Sustain (Igual que antes)\n",
    "            check_frame = min(onset_frame + 1, frame_pred.shape[0] - 1)\n",
    "            if frame_pred[check_frame, pitch] < t_frame:\n",
    "                continue \n",
    "                \n",
    "            # 3. Buscar Offset (MEJORADO)\n",
    "            end_frame = onset_frame + 1\n",
    "            # Buscamos hasta que se acabe el frame O encontremos un offset fuerte\n",
    "            while end_frame < frame_pred.shape[0]:\n",
    "                # Condici√≥n A: El frame sigue activo\n",
    "                frame_active = frame_pred[end_frame, pitch] > t_frame\n",
    "                \n",
    "                # Condici√≥n B: NO hay un offset fuerte en este punto\n",
    "                # (Si offset > t_offset, is_offset_hit es True, y paramos el loop)\n",
    "                is_offset_hit = offset_pred[end_frame, pitch] > t_offset\n",
    "                \n",
    "                if frame_active and not is_offset_hit:\n",
    "                    end_frame += 1\n",
    "                else:\n",
    "                    # Hemos encontrado el final (ya sea por ca√≠da de frame o por presencia de offset)\n",
    "                    break\n",
    "            \n",
    "            # Ajuste fino: Si paramos por un Offset, incluimos ese frame como el final\n",
    "            if end_frame < frame_pred.shape[0] and offset_pred[end_frame, pitch] > t_offset:\n",
    "                 end_frame += 1\n",
    "\n",
    "            # 4. Filtro duraci√≥n (Igual)\n",
    "            if end_frame - onset_frame > 2:\n",
    "                onset_time = onset_frame * HOP_LENGTH / SR\n",
    "                offset_time = end_frame * HOP_LENGTH / SR\n",
    "                \n",
    "                # 5. Velocity (Igual)\n",
    "                vel = 0\n",
    "                if velocity_pred is not None:\n",
    "                    vel_seg = velocity_pred[onset_frame:min(end_frame, onset_frame+5), pitch]\n",
    "                    vel = np.mean(vel_seg) if len(vel_seg) > 0 else 0\n",
    "                \n",
    "                notes.append([onset_time, offset_time, pitch + 21, vel])\n",
    "    return notes\n",
    "\n",
    "def compute_metrics_standard(ref_notes_batch, est_notes_batch):\n",
    "    total_tp, total_fp, total_fn = 0, 0, 0\n",
    "    for ref_notes, est_notes in zip(ref_notes_batch, est_notes_batch):\n",
    "        ref_arr = np.array(ref_notes)\n",
    "        est_arr = np.array(est_notes)\n",
    "        if len(ref_arr) == 0 and len(est_arr) == 0: continue\n",
    "        if len(ref_arr) == 0:\n",
    "            total_fp += len(est_arr); continue\n",
    "        if len(est_arr) == 0:\n",
    "            total_fn += len(ref_arr); continue\n",
    "\n",
    "        # Para mir_eval, columnas 0 y 1 son tiempos, columna 2 es pitch\n",
    "        ref_int, ref_p = ref_arr[:, :2], ref_arr[:, 2]\n",
    "        est_int, est_p = est_arr[:, :2], est_arr[:, 2]\n",
    "        \n",
    "        matched = mir_eval.transcription.match_notes(\n",
    "            ref_int, ref_p, est_int, est_p, onset_tolerance=0.05, offset_ratio=None\n",
    "        )\n",
    "        tp = len(matched)\n",
    "        total_tp += tp\n",
    "        total_fp += (len(est_p) - tp)\n",
    "        total_fn += (len(ref_p) - tp)\n",
    "        \n",
    "    p = total_tp / (total_tp + total_fp + 1e-8)\n",
    "    r = total_tp / (total_tp + total_fn + 1e-8)\n",
    "    f1 = 2 * p * r / (p + r + 1e-8)\n",
    "    return f1, p, r\n",
    "\n",
    "def plot_training_history(csv_path=\"training_log_kaggle.csv\"):\n",
    "    if not os.path.exists(csv_path): return\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    sns.set_theme(style=\"whitegrid\", context=\"paper\")\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "    fig.suptitle('HPPNet Optimized (Residual + PeakPicking) Metrics', fontsize=16)\n",
    "\n",
    "    sns.lineplot(data=df, x='epoch', y='train_loss', label='Train', ax=axes[0,0])\n",
    "    sns.lineplot(data=df, x='epoch', y='val_loss', label='Val', ax=axes[0,0], linestyle='--')\n",
    "    axes[0,0].set_title('Loss')\n",
    "\n",
    "    sns.lineplot(data=df, x='epoch', y='onset_f1', label='F1', ax=axes[0,1], color='g')\n",
    "    sns.lineplot(data=df, x='epoch', y='onset_p', label='Precision', ax=axes[0,1], linestyle=':', alpha=0.6)\n",
    "    sns.lineplot(data=df, x='epoch', y='onset_r', label='Recall', ax=axes[0,1], linestyle=':', alpha=0.6)\n",
    "    axes[0,1].set_title('Onset Metrics')\n",
    "\n",
    "    sns.lineplot(data=df, x='epoch', y='frame_f1', label='Frame F1', ax=axes[1,0])\n",
    "    sns.lineplot(data=df, x='epoch', y='offset_f1', label='Offset F1', ax=axes[1,0], color='orange')\n",
    "    axes[1,0].set_title('Frame & Offset F1')\n",
    "\n",
    "    sns.lineplot(data=df, x='epoch', y='velocity_mse', color='purple', ax=axes[1,1])\n",
    "    axes[1,1].set_title('Velocity MSE')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"training_results_kaggle.png\", dpi=200)\n",
    "    print(\"üìä Gr√°ficas guardadas.\")\n",
    "\n",
    "# ==========================================\n",
    "# 4. MAIN (ESTRUCTURA ORIGINAL OPTIMIZADA)\n",
    "# ==========================================\n",
    "if __name__ == \"__main__\":\n",
    "    print(f\"\\nüöÄ HPPNET-SP FINAL KAGGLE Training ({DEVICE})\")\n",
    "    print(f\"üîπ Config: Batch Size {BATCH_SIZE} | T4x2 (DataParallel) | Partial Val | Real-time Plotting\")\n",
    "    \n",
    "    # 1. Cargar Datos\n",
    "    train_ds = PianoDataset(DATA_PATH, split='train')\n",
    "    val_ds = PianoDataset(DATA_PATH, split='val')\n",
    "    \n",
    "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "    \n",
    "    # 2. Inicializar Modelo\n",
    "    model = HPPNet(in_channels=4, lstm_hidden=128).to(DEVICE)   #ANTES 3 , AHORA CAMBIA \n",
    "    \n",
    "    # --- CAMBIO: ACTIVAR MULTI-GPU ---\n",
    "    # Esto reparte el Batch Size 32 entre las dos tarjetas (16 y 16)\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(f\"üî• ¬°Activando Turbo! Usando {torch.cuda.device_count()} GPUs en DataParallel\")\n",
    "        model = nn.DataParallel(model)\n",
    "    # ---------------------------------\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=FACTOR_LR, patience=PATIENCE_LR)\n",
    "    scaler = torch.amp.GradScaler('cuda') \n",
    "    \n",
    "    # 3. Losses\n",
    "    crit_onset = FocalLoss(alpha=0.75, gamma=2.0).to(DEVICE)\n",
    "    crit_frame = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([10.0]).to(DEVICE))\n",
    "    crit_offset = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([5.0]).to(DEVICE))\n",
    "    crit_vel = nn.MSELoss(reduction='none')\n",
    "\n",
    "    # 4. Logs\n",
    "    log_file = open(\"training_log_kaggle.csv\", \"w\")\n",
    "    header = \"epoch,train_loss,val_loss,onset_f1,onset_p,onset_r,frame_f1,frame_p,frame_r,offset_f1,offset_p,offset_r,velocity_mse,lr\\n\"\n",
    "    log_file.write(header)\n",
    "    log_file.flush()\n",
    "    \n",
    "    best_f1 = 0.0\n",
    "\n",
    "    try:\n",
    "        for epoch in range(FINAL_EPOCHS):\n",
    "            model.train()\n",
    "            t_loss = 0\n",
    "            \n",
    "            # --- TRAIN ---\n",
    "            with tqdm(train_loader, desc=f\"Ep {epoch+1}/{FINAL_EPOCHS}\", leave=False) as bar:\n",
    "                for batch in bar:\n",
    "                    hcqt = batch['hcqt'].to(DEVICE)\n",
    "                    targets = {k: v.to(DEVICE) for k, v in batch.items() if k != 'hcqt'}\n",
    "                    \n",
    "                    optimizer.zero_grad()\n",
    "                    with torch.amp.autocast('cuda'):\n",
    "                        p_on, p_fr, p_off, p_vel = model(hcqt)\n",
    "                        \n",
    "                        l_on = crit_onset(p_on, targets['onset'])\n",
    "                        l_fr = crit_frame(p_fr, targets['frame'])\n",
    "                        l_off = crit_offset(p_off, targets['offset'])\n",
    "                        \n",
    "                        mask = targets['frame']\n",
    "                        l_vel = (crit_vel(torch.sigmoid(p_vel), targets['velocity']) * mask).sum() / (mask.sum() + 1e-6)\n",
    "                        \n",
    "                        loss = (10.0 * l_on) + l_fr + l_off + l_vel\n",
    "                    \n",
    "                    scaler.scale(loss).backward()\n",
    "                    scaler.unscale_(optimizer)\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                    scaler.step(optimizer)\n",
    "                    scaler.update()\n",
    "                    t_loss += loss.item()\n",
    "                    bar.set_postfix(loss=loss.item())\n",
    "            \n",
    "            avg_t_loss = t_loss / len(train_loader)\n",
    "\n",
    "            # --- ESTRATEGIA: VALIDAR CADA 3 EPOCAS ---\n",
    "            should_validate = ((epoch + 1) % 3 == 0) or ((epoch + 1) == FINAL_EPOCHS)\n",
    "\n",
    "            if should_validate:\n",
    "                # --- VAL ---\n",
    "                model.eval()\n",
    "                v_loss = 0\n",
    "                ref_all, est_all = [], []\n",
    "                fr_preds, fr_targs = [], []\n",
    "                off_preds, off_targs = [], []\n",
    "                vel_accum = 0; vel_count = 0\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    for batch in val_loader:\n",
    "                        hcqt = batch['hcqt'].to(DEVICE)\n",
    "                        targets = {k: v.to(DEVICE) for k, v in batch.items() if k != 'hcqt'}\n",
    "                        p_on, p_fr, p_off, p_vel = model(hcqt)\n",
    "                        \n",
    "                        l_on = crit_onset(p_on, targets['onset'])\n",
    "                        l_fr = crit_frame(p_fr, targets['frame'])\n",
    "                        l_off = crit_offset(p_off, targets['offset'])\n",
    "                        mask = targets['frame']\n",
    "                        l_vel = (crit_vel(torch.sigmoid(p_vel), targets['velocity']) * mask).sum() / (mask.sum() + 1e-6)\n",
    "                        \n",
    "                        v_loss += ((10.0 * l_on) + l_fr + l_off + l_vel).item()\n",
    "                        \n",
    "                        pr_on = torch.sigmoid(p_on)\n",
    "                        pr_fr = torch.sigmoid(p_fr)\n",
    "                        pr_off = torch.sigmoid(p_off)\n",
    "                        \n",
    "                        # Notes decoding\n",
    "                        for i in range(len(hcqt)):\n",
    "                            v_map = torch.sigmoid(p_vel[i]).cpu().numpy()\n",
    "                            est = tensor_to_notes(pr_on[i].cpu().numpy(), pr_fr[i].cpu().numpy(),pr_off[i].cpu().numpy(), v_map, t_onset=THRESHOLD_ONSET, t_frame=THRESHOLD_FRAME,t_offset=THRESHOLD_OFFSET)\n",
    "                            \n",
    "                            ref = []\n",
    "                            ref_on = targets['onset'][i].cpu().numpy()\n",
    "                            ref_fr = targets['frame'][i].cpu().numpy()\n",
    "                            for pitch in range(88):\n",
    "                                ons = np.where(ref_on[:, pitch] > 0.5)[0]\n",
    "                                for o in ons:\n",
    "                                    e = o + 1\n",
    "                                    while e < ref_fr.shape[0] and ref_fr[e, pitch] > 0.5: e += 1\n",
    "                                    if e - o > 1: ref.append([o*HOP_LENGTH/SR, e*HOP_LENGTH/SR, pitch+21])\n",
    "                            est_all.append(est)\n",
    "                            ref_all.append(ref)\n",
    "                        \n",
    "                        # Pixel-wise decoding\n",
    "                        fr_preds.append((pr_fr > THRESHOLD_FRAME).cpu().numpy().flatten())\n",
    "                        fr_targs.append((targets['frame'] > 0.5).cpu().numpy().flatten())\n",
    "                        \n",
    "                        off_preds.append((pr_off > THRESHOLD_OFFSET).cpu().numpy().flatten())\n",
    "                        off_targs.append((targets['offset'] > 0.5).cpu().numpy().flatten())\n",
    "                        \n",
    "                        v_p = torch.sigmoid(p_vel).cpu().numpy().flatten()\n",
    "                        v_t = targets['velocity'].cpu().numpy().flatten()\n",
    "                        m = mask.cpu().numpy().flatten().astype(bool)\n",
    "                        if m.sum() > 0:\n",
    "                            vel_accum += mean_squared_error(v_t[m], v_p[m]) * m.sum()\n",
    "                            vel_count += m.sum()\n",
    "\n",
    "                # --- METRICS ---\n",
    "                avg_v_loss = v_loss / len(val_loader)\n",
    "                \n",
    "                onset_f1, onset_p, onset_r = compute_metrics_standard(ref_all, est_all)\n",
    "                \n",
    "                f_p = np.concatenate(fr_preds); f_t = np.concatenate(fr_targs)\n",
    "                frame_f1 = f1_score(f_t, f_p, zero_division=0)\n",
    "                frame_p = precision_score(f_t, f_p, zero_division=0)\n",
    "                frame_r = recall_score(f_t, f_p, zero_division=0)\n",
    "                \n",
    "                o_p = np.concatenate(off_preds); o_t = np.concatenate(off_targs)\n",
    "                offset_f1 = f1_score(o_t, o_p, zero_division=0)\n",
    "                offset_p = precision_score(o_t, o_p, zero_division=0)\n",
    "                offset_r = recall_score(o_t, o_p, zero_division=0)\n",
    "                \n",
    "                vel_mse = vel_accum / (vel_count + 1e-8)\n",
    "                curr_lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "                print(\"-\" * 80)\n",
    "                print(f\"üèÅ Epoch {epoch+1} Results:\")\n",
    "                print(f\"   üìâ Loss    : Train={avg_t_loss:.4f} | Val={avg_v_loss:.4f}\")\n",
    "                print(f\"   üéπ Onset   : F1={onset_f1:.4f} | P={onset_p:.4f} | R={onset_r:.4f}\")\n",
    "                print(f\"   üñºÔ∏è Frame   : F1={frame_f1:.4f} | P={frame_p:.4f} | R={frame_r:.4f}\")\n",
    "                # AQUI EST√Å LA METRICA QUE FALTABA\n",
    "                print(f\"   üèÅ Offset  : F1={offset_f1:.4f} | P={offset_p:.4f} | R={offset_r:.4f}\")\n",
    "                print(f\"   ‚ö° Vel     : MSE={vel_mse:.4f}\")\n",
    "                print(f\"   üß† LR      : {curr_lr:.2e}\")\n",
    "                print(\"-\" * 80)\n",
    "                \n",
    "                log_line = f\"{epoch+1},{avg_t_loss},{avg_v_loss},{onset_f1},{onset_p},{onset_r},{frame_f1},{frame_p},{frame_r},{offset_f1},{offset_p},{offset_r},{vel_mse},{curr_lr}\\n\"\n",
    "                \n",
    "                scheduler.step(onset_f1)\n",
    "                \n",
    "                if onset_f1 > best_f1:\n",
    "                    best_f1 = onset_f1\n",
    "                    # Guardado seguro con DataParallel\n",
    "                    state_dict = model.module.state_dict() if isinstance(model, nn.DataParallel) else model.state_dict()\n",
    "                    torch.save(state_dict, \"best_hppnet_kaggle.pth\")\n",
    "                    print(f\"   üíæ Nuevo R√©cord! Modelo guardado (F1: {best_f1:.4f})\")\n",
    "\n",
    "                # --- GUARDAR GR√ÅFICA EN TIEMPO REAL ---\n",
    "                log_file.write(log_line)\n",
    "                log_file.flush()\n",
    "                # Llamamos a plot aqu√≠ para que se actualice la imagen png cada vez que validamos\n",
    "                plot_training_history(\"training_log_kaggle.csv\")\n",
    "                print(\"   üìä Gr√°fica actualizada.\")\n",
    "\n",
    "            else:\n",
    "                # --- NO VALIDAR (Ahorro de tiempo) ---\n",
    "                print(f\"‚è© Epoch {epoch+1}: Train Loss={avg_t_loss:.4f} (Validaci√≥n saltada)\")\n",
    "                # Log con huecos vac√≠os para mantener formato CSV\n",
    "                log_line = f\"{epoch+1},{avg_t_loss},,,,,,,,,,,,{optimizer.param_groups[0]['lr']}\\n\"\n",
    "                log_file.write(log_line)\n",
    "                log_file.flush()\n",
    "                \n",
    "                # Guardar backup simple\n",
    "                state_dict = model.module.state_dict() if isinstance(model, nn.DataParallel) else model.state_dict()\n",
    "                torch.save(state_dict, \"latest_checkpoint.pth\")\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nüõë Entrenamiento detenido.\")\n",
    "        \n",
    "    finally:\n",
    "        log_file.close()\n",
    "        # Asegurar gr√°fica final\n",
    "        plot_training_history(\"training_log_kaggle.csv\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
