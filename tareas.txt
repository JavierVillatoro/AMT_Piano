----------TAREAS---------
1.EDA , cuantas obras de cuantos compositores?

Cambiar todo el dataset de .midi a mid , hacer una funcion para esto.
Pedir cuando esto este desordenado a gemini que me lo ordene

Tener en cuenta el padding , todas las piezas son de diferente duracion y tambien los midi 
, incluso de entre ellas.

-------Cambio de monofonoico a polifonico---------
Antes(monofonico): Salida (Batch, Time, 1). Activación: Softmax (la suma da 1).
Ahora(polifonico): Salida (Batch, Time, 88). Activación: Sigmoid.

AMT_Piano_Sheet_Music/
│
├── data/                       <-- TU CARPETA ACTUAL (Datos Crudos)
│   └── maestro-v3.0.0/         
│       ├── 2004/
│       ├── 2006/
│       └── ...
│
├── processed_data/             <-- NUEVA CARPETA (Datos Listos para la IA)
│   │
│   ├── inputs_cqt/             <-- Input X: Los tensores de audio (CQT o Mel)
│   │
│   └── targets/                <-- Label Y: Aquí está la magia de "Onsets & Frames"
│       ├── frames/             <-- Piano Roll normal (sostenido)
│       ├── onsets/             <-- Solo el momento del ataque (golpe)
│       └── velocities/         <-- (Opcional) La fuerza de la nota (0-127)
│
├── scripts/
│   ├── 01_renombrar.py         <-- El que ya tienes
│   └── 02_preprocess.py        <-- El script que generará los datos
│
└── train.py

ver paper google magenta onset and frames

Nonnegative matrix factorization (NMF)

Tener en cuenta el suggested train/validation/test split.


VRAM (8GB vs 80GB): Aunque 8GB es suficiente para cargar este modelo ligero (5.9M parámetros), 
tendrás que usar un batch size mucho menor (probablemente 4 u 8, en lugar de 16 o 32). 
Esto hace que el entrenamiento sea más inestable y lento porque la tarjeta tiene que hacer más "viajes" para procesar la misma cantidad de datos.

puedo hacer en google collab u otro medio mas sencillo?

Visualizar con cqt los audios , ver si usar unet (imagenes medicas, para el atack y el release)

add my own data , play piano and try different midi notes. 

prompt: podrias explicarme de manera creativa esta arquitectura , para que mi abuela pudiera entenderlo?

Usar dataloader de pytorch para cargar solo lo que necesito al momento

Añadir partitura para prueba.

Añadir dataset propio , grabar con yamaha.

Utilizar frame_ex.

Problema con mucho cero --- ¿Cómo se arregla? Usando Loss Functions ponderadas (Weighted Loss) durante el entrenamiento.

Eliminar ruido de principio de todos los wavs , recortarlos con los midi

Ver pedal ? añadir otros movimientos?

Add optuna

Dataset ahora entrena y quita los que nos son iguales