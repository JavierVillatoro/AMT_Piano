# üéπ AMT Piano Sheet Music - Proyecto de Transcripci√≥n (Deep Learning)

Este proyecto implementa un sistema de **Automatic Music Transcription (AMT)** para piano utilizando una arquitectura h√≠brida **CRNN (Convolutional Recurrent Neural Network)**. 

El modelo convierte audio (`.wav`) a MIDI (`.mid`) prediciendo no solo las notas, sino tambi√©n su duraci√≥n exacta y din√°mica (velocity).

---

## üöÄ Pipeline de Ejecuci√≥n (Orden Correcto)

### 1. Preparaci√≥n de Datos
* **Script:** `01_rename_midi.py`
    * **Funci√≥n:** Normaliza las extensiones de `.midi` a `.mid`.
* **Script:** `02_resample_in_place.py`
    * **Funci√≥n:** Convierte todo el dataset MAESTRO a **16.000 Hz (Mono)**. Sobrescribe los originales para ahorrar espacio.

### 2. Preprocesamiento (CQT / HCQT)
* **Script:** `03_preprocess_multichannel_fixed.py` (Recomendado)
    * **Funci√≥n:** Convierte audio en espectrogramas.
    * **Modos:**
        * `Opci√≥n 1 (CQT)`: 1 Canal. Est√°ndar.
        * `Opci√≥n 2 (HCQT)`: 3 Canales (Fundamental, 2¬∫ Arm√≥nico, 3¬∫ Arm√≥nico). *Mejor calidad.*
    * **Fix:** Incluye padding con ceros para frecuencias que superan el l√≠mite de Nyquist (8kHz).

### 3. Entrenamiento (Full-Stack)
* **Script:** `06_training_full.py`
    * **Arquitectura:** U-Net (Encoder/Decoder) + BiLSTM (Contexto Temporal).
    * **Cabezas de Salida (4 Heads):**
        1.  `Onset`: ¬øEmpieza una nota?
        2.  `Frame`: ¬øSe mantiene la nota?
        3.  `Offset`: ¬øAcaba la nota? (Para precisi√≥n en la duraci√≥n).
        4.  `Velocity`: Din√°mica/Volumen (0-127).
    * **Optimizaciones:**
        * `Smart Sampling`: El Dataset ignora fragmentos de silencio.
        * `Masked Loss`: Solo entrenamos la velocity cuando realmente hay una nota.
        * `Pos_weight`: Balanceo de clases (10x peso a los Onsets).

### 4. Inferencia (Audio -> MIDI)
* **Script:** `07_inference_full.py`
    * **Funci√≥n:** Genera el archivo MIDI final.
    * **Caracter√≠sticas:**
        * Autodetecta formato (MP3/WAV) y convierte a 16kHz.
        * Aplica **Padding** para evitar errores de tama√±o en la U-Net.
        * Usa `Onset` + `Frame` + `Offset` para cortar las notas con precisi√≥n milim√©trica.
        * Asigna la **Velocity real** predicha por el modelo (no random).
    * **Salida:** Guarda los resultados en la carpeta `mis_midis_generados`.

---

## üß† Arquitectura del Modelo (`PianoCRNN`)

La red neuronal procesa ventanas de audio de ~10 segundos (320 frames).

| Componente | Configuraci√≥n |
| :--- | :--- |
| **Input** | `(Batch, 1, 320, 88)` o `(Batch, 3, 320, 88)` |
| **Encoder** | 3 Bloques Convolucionales con MaxPool (solo en tiempo `2x1`). |
| **Bottleneck** | BiLSTM (Bidireccional) con 128 unidades ocultas. |
| **Decoder** | 3 Bloques con Skip Connections (estilo U-Net). |
| **Salida** | 4 Matrices de Probabilidad `(Time, 88)`. |

---

## üõ†Ô∏è Soluci√≥n de Errores Comunes

1.  **Error de Nyquist en Preprocess:**
    * *Causa:* Intentar calcular el 3er arm√≥nico de notas agudas (>8kHz).
    * *Soluci√≥n:* El script `fixed` rellena esas frecuencias con ceros.

2.  **RuntimeError: Sizes of tensors must match... (Inferencia):**
    * *Causa:* El audio tiene una longitud impar que no cuadra con el MaxPool.
    * *Soluci√≥n:* `07_inference_full.py` aplica padding autom√°tico para que sea m√∫ltiplo de 4.

3.  **OSError con MP3 (Windows):**
    * *Causa:* Arrastrar archivos a PowerShell a√±ade `&` y comillas.
    * *Soluci√≥n:* El script de inferencia limpia autom√°ticamente la ruta del archivo.

---

## üì¶ Librer√≠as Necesarias
```bash
pip install torch torchvision torchaudio --index-url [https://download.pytorch.org/whl/cu118](https://download.pytorch.org/whl/cu118)
pip install numpy librosa pretty_midi soundfile tqdm scikit-learn matplotlib seaborn
# Opcional para MP3 en Windows:
# winget install ffmpeg


Inference_full.py